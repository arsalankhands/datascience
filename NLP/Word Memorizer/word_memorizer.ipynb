{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "748bf5f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transcribe_audio():\n",
    "    \n",
    "    from deepspeech import Model\n",
    "    import numpy as np\n",
    "    import os\n",
    "    import wave\n",
    "    import json\n",
    "    import pyaudio\n",
    "    import io\n",
    "\n",
    "\n",
    "    chunk = 1024  # Record in chunks of 1024 samples\n",
    "    sample_format = pyaudio.paInt16  # 16 bits per sample\n",
    "    channels = 1\n",
    "    fs = 16000  \n",
    "    seconds = 15\n",
    "\n",
    "    p = pyaudio.PyAudio()  # Create an interface to PortAudio\n",
    "\n",
    "    print('Recording for {} seconds'.format(seconds))\n",
    "\n",
    "\n",
    "    stream = p.open(format=sample_format,\n",
    "                    channels=channels,\n",
    "                    rate=fs,\n",
    "                    frames_per_buffer=chunk,\n",
    "                    input=True)\n",
    "\n",
    "    frames = []  # Initialize array to store frames\n",
    "\n",
    "    # Store data in chunks for 15 seconds\n",
    "    for i in range(0, int(fs / chunk * seconds)):\n",
    "        data = stream.read(chunk)\n",
    "        frames.append(data)\n",
    "\n",
    "    # Stop and close the stream \n",
    "    stream.stop_stream()\n",
    "    stream.close()\n",
    "    # Terminate the PortAudio interface\n",
    "    p.terminate()\n",
    "\n",
    "    print('Stopped.')\n",
    "\n",
    "    # Save the recorded data as a WAV file but don't save it in storage\n",
    "    # Use IO library to store the WAV file in temporary format\n",
    "    container = io.BytesIO()\n",
    "    wf = wave.open(container, 'wb')\n",
    "    wf.setnchannels(channels)\n",
    "    wf.setsampwidth(p.get_sample_size(sample_format))\n",
    "    wf.setframerate(fs)\n",
    "    wf.writeframes(b''.join(frames))\n",
    "    wf.close()\n",
    "\n",
    "    # Read the data up to this point\n",
    "    container.seek(0)\n",
    "    data_package = container.read()\n",
    "    \n",
    "\n",
    "    #load the pre-trained deep speech model and scorer from the same directory (need to download from the DeepSpeech website)\n",
    "    DEEPSPEECH_MODEL_DIR = 'deepspeech'\n",
    "    MODEL_FILE_PATH = os.path.join(DEEPSPEECH_MODEL_DIR, 'deepspeech-0.9.3-models.pbmm')\n",
    "    SCORER_FILE_PATH = os.path.join(DEEPSPEECH_MODEL_DIR, 'deepspeech-0.9.3-models.scorer')\n",
    "    beam_width = 100\n",
    "    lm_alpha = 0.93\n",
    "    lm_beta = 1.18\n",
    "\n",
    "    model = Model(MODEL_FILE_PATH)\n",
    "    model.enableExternalScorer(SCORER_FILE_PATH)\n",
    "    model.setScorerAlphaBeta(lm_alpha, lm_beta)\n",
    "    model.setBeamWidth(beam_width)\n",
    "    \n",
    "    data = np.frombuffer(data_package, np.int16)\n",
    "    #Perform transcription of audio wave file\n",
    "    text = model.stt(data)\n",
    "    return text\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d2a07672",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity(text1, text2):\n",
    "    #Use the sentence transformers like to load a pre-trained BERT model for text-vector embeddings\n",
    "    from sentence_transformers import SentenceTransformer\n",
    "    #Cosine similiarity method from sk-learn compares the vector embeddings for semantic similarity \n",
    "    from sklearn.metrics.pairwise import cosine_similarity\n",
    "    model = SentenceTransformer('bert-base-nli-mean-tokens')\n",
    "    sentence_embeddings = model.encode([text1,text2])\n",
    "    similiarity=cosine_similarity([sentence_embeddings[0]], sentence_embeddings[1:])\n",
    "    return similiarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "6c2c5a5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_memorized(df, name):\n",
    "    from time import sleep\n",
    "    from datetime import date\n",
    "    #If cosine_similarity >= 0.80 -> word memorized\n",
    "    #If cosine_similarity < 0.80 -> you need to revise this word\n",
    "    name = str(name)\n",
    "    today = str(date.today())\n",
    "    memorized_words = []\n",
    "    not_memorized_words = []\n",
    "    for i in range(len(df)):\n",
    "        word = df.iloc[i].word\n",
    "        definition = df.iloc[i].definition\n",
    "        try:\n",
    "            import random\n",
    "            choice=random.choice([1,2])\n",
    "            if choice==1:\n",
    "                answer_given = input('Write the definition for {}: '.format(word.upper()))\n",
    "            else:\n",
    "                print('Record the definition for {}:'.format(word.upper()))\n",
    "                sleep(10)   \n",
    "                answer_given = transcribe_audio()\n",
    "\n",
    "            similiarity=cosine_similarity(definition, answer_given)\n",
    "            similiarity_word = cosine_similarity(word, answer_given)\n",
    "            if (similiarity>=0.8) or (similiarity_word>=0.8):\n",
    "                print('Word {} memorized'.format(word.upper()))\n",
    "                memorized_words.append(word)\n",
    "            else:\n",
    "                print('Word {} not memorized yet or properly \\ncorrect definition: {}\\nyour answer {}:\\nscore:{}'.format(word.upper(), definition, answer_given.upper(), similiarity))\n",
    "                not_memorized_words.append(word)\n",
    "        except KeyboardInterrupt:\n",
    "            print ('KeyboardInterrupt exception is caught')\n",
    "    if len(not_memorized_words)!=0:\n",
    "        df_not_memorized = df.loc[df.word.isin(not_memorized_words)]\n",
    "        df_not_memorized.to_csv('{}-{}-not-memorized.csv'.format(name.lower(),today), index=False)\n",
    "    if len(memorized_words)!=0:\n",
    "        df_memorized = df.loc[df.word.isin(memorized_words)]\n",
    "    return not_memorized_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "20348dc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "#data = pd.read_csv('words_with_definitions.csv')\n",
    "data['word'] = data['word'].str.strip()\n",
    "data['definition'] = data['definition'].str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "1144d68e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Record the definition for FEASIBLE:\n",
      "Recording for 15 seconds\n",
      "Stopped.\n",
      "Word FEASIBLE not memorized yet or properly \n",
      "correct definition: possible to do easily or conveniently\n",
      "your answer :\n",
      "score:[[0.5208689]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['feasible']"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_memorized(data.sample(1),'Arsalan')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ds]",
   "language": "python",
   "name": "conda-env-ds-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
